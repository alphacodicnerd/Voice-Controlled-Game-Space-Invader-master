{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join, dirname\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson.websocket import RecognizeCallback, AudioSource\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('yTSSJ5GSmGhgIA95KnVPDf61KSZinztq909UBMfoqh7l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_to_text = SpeechToTextV1(authenticator=authenticator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_to_text.set_service_url(\"https://api.us-east.speech-to-text.watson.cloud.ibm.com/instances/77c94867-643f-431b-a593-0bc775c18bb7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 2\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 3\n",
    "filename = \"output.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRecognizeCallback(RecognizeCallback):\n",
    "    def __init__(self):\n",
    "        RecognizeCallback.__init__(self)\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print(json.dumps(data, indent=2))\n",
    "\n",
    "    def on_error(self, error):\n",
    "        print('Error received: {}'.format(error))\n",
    "\n",
    "    def on_inactivity_timeout(self, error):\n",
    "        print('Inactivity timeout: {}'.format(error))\n",
    "\n",
    "\n",
    "myRecognizeCallback = MyRecognizeCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Recording\nFinished recording\n"
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "print('Recording')\n",
    "\n",
    "stream = p.open(format=sample_format,\n",
    "                channels=channels,\n",
    "                rate=fs,\n",
    "                frames_per_buffer=chunk,\n",
    "                input=True)\n",
    "\n",
    "frames = []  # Initialize array to store frames\n",
    "\n",
    "# Store data in chunks for 3 seconds\n",
    "for i in range(0, int(fs / chunk * seconds)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop and close the stream \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# Terminate the PortAudio interface\n",
    "p.terminate()\n",
    "\n",
    "print('Finished recording')\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(filename, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "wf.setframerate(fs)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open('output.wav','rb')\n",
    "audio_source = AudioSource(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\n  \"results\": [\n    {\n      \"keywords_result\": {},\n      \"alternatives\": [\n        {\n          \"confidence\": 0.99,\n          \"transcript\": \"okay \"\n        }\n      ],\n      \"final\": true\n    }\n  ],\n  \"result_index\": 0\n}\nNone\n<class 'NoneType'>\n"
    }
   ],
   "source": [
    "\n",
    "result = speech_to_text.recognize_using_websocket(\n",
    "                            audio=audio_source,\n",
    "                            content_type='audio/wav',\n",
    "                            recognize_callback=myRecognizeCallback,\n",
    "                            model='en-US_BroadbandModel',\n",
    "                            keywords=['left', 'right', 'up','down'],\n",
    "                            keywords_threshold=0.25,\n",
    "                            max_alternatives=1)\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}